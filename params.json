{
  "name": "Panorama",
  "tagline": "image stitching",
  "body": "# panorama\r\npanorama creator  \r\n![img](https://github.com/yihui-he/panorama/blob/master/results/intersection.jpg)  \r\n![img](https://github.com/yihui-he/panorama/blob/master/results/GrandCanyon2.jpg)  \r\n![img](https://github.com/yihui-he/panorama/blob/master/results/redrock.jpg)  \r\n### bonus  \r\nI implemented all of the elaborate features described in **BONUS** part.  \r\n- I'm able to handle 360 panorama.\r\n- Random sequence of images input is welcomed.\r\n- I use color blending and smoothing to make the image more continuous.  \r\n\r\n### how to run  \r\nimages files are already in ./imgs  \r\n- If you want to see results directly, go to ./results folder\r\n- If you want to test all images sets with only one click,run RunAllDatasets.m.(This may run 10 more minutes, because I didn't resize large images. If I have more time, I can add this feature)  \r\n- If you want to specify the image folder, run main.m with path to images folder as argument(as described in assignment)  \r\n\r\n**Note that**, if you use the last way to run my code, the folder names should be as follows(I need to tune focus on each image set)  \r\n'ucsb4','family_house','glacier4','yellowstone2','GrandCanyon1','yellowstone5','yellowstone4','west_campus1','redrock','intersection','GrandCanyon2'  \r\nFor example:  \r\n`main('./imgs/ucsb4/');`\r\n\r\n######details of my algorithms are shown below:  \r\n\r\n### 360 panorama\r\n- [x] mapping image to cylindrical coordinate\r\n\r\n### recognize panorama(random inputs)\r\nI select two random sequence images set:family\\_house, and west\\_campus1  \r\nThey are already shuffled. You can see them in imgs folder.  \r\nOr you can run shuffle.bash to shuffle them again.  \r\nAs described in Brown's paper, I use $N\\_inlier>k\\*N\\_pairs+b$ to compute whether a pair of images match or not  \r\nk,b are const. Set to 5.9 and 0.22 respectively.  \r\n\r\n### merging and blending  \r\n- [x] Alpha  \r\n- [ ] Pyramid  \r\n- [x] Noblend\r\n\r\n\r\n### transformation\r\n- [x] homography transformation.\r\n- [x] translation transformation.( This is more robust)\r\n\r\n### matching\r\n- [x] RANSAC\r\n- [ ] exposure matching  \r\n\r\n### global adjustment\r\n- [x] end to end adjustment(comput shift and subtract shift/n to each image)  \r\n- [ ] bundle adjustment(difficult way)  \r\n\r\n### getting features\r\n- [x] use SIFT features(using VLFeat library, professor allowed)  \r\n- [x] SURF features, (SIFT is better)  \r\n\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}